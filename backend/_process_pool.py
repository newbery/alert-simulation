from concurrent import futures

from fastapi import BackgroundTasks

from .redis_helpers import connect, reset_counts, read_counts, update_counts
from .settings import Config, Settings
from .messenger import generate_message, generate_phone_number, send_message


async def init(config: Config, settings: Settings, background: BackgroundTasks) -> None:
    """Initialize the simulation setup"""
    # All work is done during 'start'
    pass


async def ready(config: Config, settings: Settings) -> dict:
    """Check if the simulation setup is ready"""
    # Again, nothing to wait for
    return {"ready": True}


async def start(
    config: Config, settings: Settings, background: BackgroundTasks
) -> None:
    """Start the simulation"""
    background.add_task(start_tasks, config, settings)


async def status(config: Config) -> dict:
    """Get the running results of the simulation"""
    return read_counts(connect())


async def reset(config: Config) -> None:
    """Teardown/reset the simulation"""
    global _executor
    if _executor is not None:
        # This little shuffle is to avoid a potential race condition
        # in the loop that is adding more tasks to the executor.
        # It turns off the loop before shutting down the executor.
        executor, _executor = _executor, None
        executor.shutdown(wait=True, cancel_futures=True)
    reset_counts(connect())


# Needed by "reset" to acquire the executor generated by "start_tasks"
_executor: futures.Executor | None = None


def start_tasks(config: Config, settings: Settings) -> None:
    """Start all the message tasks using a locally managed pool of processes"""
    global _executor
    redis = connect()
    tasks = []

    number_of_processes = settings.number_of_processes
    number_of_messages = settings.number_of_messages

    kwargs = {
        "time_mean": config.message_time_mean,
        "time_stdev": config.message_time_stdev,
        "failure_rate": settings.failure_rate,
    }

    def update(task):
        try:
            delay, failed = task.result()
            update_counts(redis, delay, failed)
        except futures.CancelledError:
            # We can get here after a reset, so just ignore it
            pass

    with futures.ProcessPoolExecutor(max_workers=number_of_processes) as executor:
        _executor = executor
        for _ in range(number_of_messages):
            if _executor is not None:
                task = executor.submit(message_task, **kwargs)
                task.add_done_callback(update)
                tasks.append(task)
        futures.wait(tasks)


def message_task(
    *, time_mean: float, time_stdev: float, failure_rate: float
) -> tuple[float, float]:
    message = generate_message()
    phone_number = generate_phone_number()
    delaydist = (time_mean, time_stdev)
    delay, failed = send_message(message, phone_number, failure_rate, delaydist)
    return delay, failed
